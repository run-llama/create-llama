name: Release llama-index-server

on:
  push:
    branches:
      - main
    paths:
      - "python/llama-index-server/**"
      - ".github/workflows/release_llama_index_server.yml"
  pull_request:
    types:
      - closed

concurrency: ${{ github.workflow }}-${{ github.ref }}

jobs:
  prepare-ui:
    name: Prepare Frontend Assets
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version: "20"

      - name: Install pnpm
        run: npm install -g pnpm

      - name: Install frontend dependencies
        working-directory: packages/server
        run: pnpm install

      - name: Build frontend statics
        working-directory: packages/server
        run: pnpm build

      - name: Upload frontend statics
        uses: actions/upload-artifact@v4
        with:
          name: frontend-statics
          path: packages/server/dist/static/
          if-no-files-found: error

  release:
    name: Create Release PR
    runs-on: ubuntu-latest
    defaults:
      run:
        working-directory: ./python/llama-index-server
    if: |
      github.event_name == 'push' && 
      !startsWith(github.ref, 'refs/heads/release/llama-index-server-v') &&
      !contains(github.event.head_commit.message, 'Release: llama-index-server v')

    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Download frontend statics
        run: |
          echo "Downloading frontend statics from run ${{ github.run_id }}"
          gh run download ${{ github.run_id }} --name frontend-statics -D llama_index/server/static_ui
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}

      - name: Install uv
        uses: astral-sh/setup-uv@v5
        with:
          enable-cache: true

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install dependencies
        shell: bash
        run: uv sync --all-extras --dev

      - name: Setup Git
        run: |
          git config --global user.email "github-actions[bot]@users.noreply.github.com"
          git config --global user.name "github-actions[bot]"

      - name: Bump patch version
        shell: bash
        run: |
          uvx --from=toml-cli toml set --toml-path=pyproject.toml project.version $(uvx --from=toml-cli toml get --toml-path=pyproject.toml project.version | awk -F. '{$NF = $NF + 1;}1' OFS=.)
          git add pyproject.toml
          git commit -m "chore(release): bump llama-index-server version to $(uvx --from=toml-cli toml get --toml-path=pyproject.toml project.version)"

      - name: Get current version
        id: get_version
        shell: bash
        run: |
          version=$(uvx --from=toml-cli toml get --toml-path=pyproject.toml project.version)
          echo "current_version=${version}" >> "$GITHUB_OUTPUT"

      - name: Create Release PR
        uses: peter-evans/create-pull-request@v6
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
          commit-message: "Release: llama-index-server v${{ steps.get_version.outputs.current_version }}"
          title: "Release: llama-index-server v${{ steps.get_version.outputs.current_version }}"
          body: |
            This PR was automatically created to release a new version of the llama-index-server package.

            Version: ${{ steps.get_version.outputs.current_version }}

            Please review the changes and merge to trigger the release.
          branch: release/llama-index-server-v${{ steps.get_version.outputs.current_version }}
          base: main
          labels: release, llama-index-server

  publish:
    name: Publish to PyPI
    needs: [prepare-ui]
    runs-on: ubuntu-latest
    defaults:
      run:
        working-directory: ./python/llama-index-server
    if: |
      github.event_name == 'pull_request' && 
      github.event.pull_request.merged == true && 
      startsWith(github.event.pull_request.title, 'Release: llama-index-server') &&
      startsWith(github.event.pull_request.head.ref, 'release/llama-index-server-v')

    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4

      - name: Download frontend statics
        uses: actions/download-artifact@v4
        with:
          name: frontend-statics
          path: packages/server/dist/static/

      - name: Install uv
        uses: astral-sh/setup-uv@v5
        with:
          enable-cache: true

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install dependencies
        shell: bash
        run: uv sync --all-extras

      - name: Get current version
        id: get_version
        shell: bash
        run: |
          version=$(uvx --from=toml-cli toml get --toml-path=pyproject.toml project.version)
          echo "current_version=${version}" >> "$GITHUB_OUTPUT"

      - name: Build package
        shell: bash
        run: uv build --no-sources --wheel

      - name: Validate built wheel has static files
        shell: bash
        run: |
          wheel_file=$(ls dist/*.whl)
          unzip -l $wheel_file | grep -q "static/index.html"

      - name: Publish to PyPI
        shell: bash
        run: uv publish --token ${{ secrets.PYPI_TOKEN }}

      - name: Create GitHub Release
        uses: softprops/action-gh-release@v2
        with:
          tag_name: llama-index-server-v${{ steps.get_version.outputs.current_version }}
          name: "llama-index-server v${{ steps.get_version.outputs.current_version }}"
          body: |
            Release of llama-index-server v${{ steps.get_version.outputs.current_version }}
          draft: false
          prerelease: false
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
